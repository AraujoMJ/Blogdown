---
title: "Análise de Regressão"
output: html_document
date: 2021-12-07T11:55:12-08:00
---


## 1. Introdução 

**Análise de regressão** é uma técnica ***estatística*** que permite examinar e modelar a [**relação entre variáveis**]{style="color: green"}. A análise de regressão é amplamente aplicada em várias áreas do conhecimento (engenharias, ciências da física química, economia, administração, ciências biológicas e da vida, ciências sociais etc.).\

Em um contexto geral, em uma análise de regressão, determinamos o grau em que as variáveis independentes (Variável preditora ou regressora **x**) influenciam as variáveis dependentes (Vaiável resposta **y**). Por exemplo, utilizamos uma análise de regressão para determinar como o crescimento das plantas de um clone comercial de eucalipto, medido em [**altura**]{style="color: blue"} (**y**), é influenciado ou está intimamente relacionado às [**doses**]{style="color: red"} de um determinado fertilizante (**x**). Outro exemplo, utilizamos um modelo de regressão para obtemos uma equação hipsiométrica para a predição de volume de madeira com base em dados de **DAP** e **Altura** mensurados na floresta.

Para mais detalhes sobre análise de regressão, ver [Montgomery *et. al* (2021)](#Referências)

## 2. Modelo de Regressão

**Notas:** 

* Nesta aula utilizaremos algumas expressões para escrever algumas equações. Para conhecer algumas sintaxes dessas espressões, acesse a lista em [Mathematical Annotation in R](https://stat.ethz.ch/R-manual/R-devel/library/grDevices/html/plotmath.html)\

* Baixem o pacote `equatiomatic`

```{r equation}
# install.packages("equatiomatic")
```

Podemos definir um modelo de regressão como uma forma algébrica de descrever a variação de uma variável resposta **y** (dependente) em relação a uma variável peditora ou regressora **x** (independente). Suponhamos, por exemplo, ver como as variáveis 'x' e 'y' estão associadas, isto é, para cada valor de 'x' existe um valor de 'y'. Isso permite averiguar: **para cada variação de 'x', qual o valor de 'y'?**.

Para isso, vamos criar um *dataset*...  
```{r dt1}
# Criando um dataset
dt1 <- data.frame(x = 1:10, y = 1:10)
dt1
```

...e plotar o gráfico.  

```{r Plot 1}
# Plotando o gráfico com 'labels' nos eixos
plot(dt1$y ~ dt1$x, xlab = "Variável regressora 'x'", ylab = "Variável resposta 'y'")

# Escrevendo o título do gráfico
mtext(expression(paste("y = ", hat(y), " = b0 + b1x")))

# Plotando a linha, fornecendo o intercepto (b0 = 0) e a inclinação (b1 = 1) da reta
abline(0, 1)
```

Nota-se que há uma associação perfeita e, que, podemos reproduzir 'y' **exatamente** pela equação obtida, isto é, a reta **"passa"** por todos os pontos dos dados. Há um ajuste perfeito nesse modelo. Contudo, em um ambiente prático, teremos **mais de um valor/observação** para a variável regressora 'x', associado à uma variável resposta 'y'.


Para vericar, vamos criar um outro *dataset* com essas características...  
```{r dt2}
# Configurar a semente
set.seed(123)

# Simulação da variável resposta 'Y'
Y <- list()
for (i in c(11:20)) {
  Y[[i]] <- rnorm(3, i, 1)
}

# Conbvertendo a lista em um vetor
Y <- unlist(Y)

# Conjunto de dados
dt2 <- data.frame(x = rep(1:10, each = 3), y = Y)
dt2
```

...e novamente plotar o gráfico.  

```{r Plot 2}
# Plotando o gráfico com 'labels' nos eixos
plot(dt2$y ~ dt2$x, xlab = "Variável regressora 'x'", ylab = "Variável resposta 'y'")

# Escrevendo o título do gráfico
mtext(expression(paste(y != hat(y), " = b0 + b1x + ", bold(e))))

# Obtendo a reta
abline(lm(dt2$y ~ dt2$x))
```

### 2.1. Diagnóstico da Reta

Para a obtenção da Reta utilizamos a função `lm`, a qual é usada para ajustar um modelo linear (vide [R Documentation](https://www.rdocumentation.org/packages/tram/versions/0.6-0/topics/Lm)). Como resultado, obtemos uma lista composta por objetos, tais como, **coeficientes** estimados (intercepto, inclinação), **resíduos** entre outros.
Como possuímos mais de um valor da variável resposta ('y') para um dado valor da variável regressora ('x'), não conseguimos reproduzir/obter 'y' com o modelo apresentado anteriormente: 
$y=\beta_0 \ + \beta_1$, pois, há um **erro** (resíduos) associado, o qual, representa a variabilidade presente nos dados, em que a variável regressora, não explica toda a variação.

Antes de adentrar ao aspecto do ajuste do modelo de regressão e particularidades dos resíduos, vamos compreender como o modelo de regressão, com o ajuste da variável resposta em função de uma variável regressora, é melhor em comparação ao uso somente da média.

Na figura abaixo, temos a [***linha vermelha***]{style="color: red"} indicando a **Média Geral** dos dados, isto é, um valor médio de 'y' para **TODOS OS VALORES** de 'x'. O fator residual, representa o desvio em relação à média geral [(**Reta vermelha**)]{style="color: red"}. 

Nesse modelo, a variabilidade dos dados é obtida em relação à média geral (***M***), isto é, o somatório da diferença de cada **'y'** em relação à ***M*** e, elevando o valor obtido ao quadrado. A isto denominamos de *Soma de Quadrados Total* (***SQT***). A notação matemática é:

$$
SQT=\sum (Y_i\ - \bar{Y_i)}^2
$$
Em suma, a porção que o modelo não explica, isto é, **um modelo de média apenas**, é igual a ***SQT***

* Modelo de média apenas

```{r Reta 1}
# Plotando o gráfico com 'labels' nos eixos
plot(dt2$y ~ dt2$x, xlab = "Variável regressora 'x'", ylab = "Variável resposta 'y'")

# Escrevendo o título do gráfico
mtext(expression(paste(y != hat(y), " = b0 + b1x + ", bold(e))))
mtext("1)", side = 3, adj = 0)

  ## Reta da média geral
abline(h = mean(dt2$y), col = "red")
text(paste("__ Média Geral (", round(mean(dt2$y), 2), ")"), x = 3, y = 19, col = "red")

# Obtendo a soma de quadrados totais ==> SQT
SQT <- sum((dt2$y - mean(dt2$y))^2)

# Escrevendo SQT no gráfico
text(paste("SQT = ", round(SQT, 2)), x = 8, y = 13, col = "red")

```

Agora, observaremos o quão o uso do modelo de regressão é melhor em relação ao modelo de média para explicar a associação entre variáveis.

Na figura abaixo, temos a [***linha azul***]{style="color: blue"} indicando a **Reta ajustada com o modelo linear**, isto é, um valor médio de 'y' para **CADA VALOR** de 'x'. O fator residual, representa o desvio em relação à média para cada variável regressora [(**Reta azul**)]{style="color: blue"}.

Neste modelo, à uma variabilidade residual em relação à média de cada valor da variável regressora 'x', o qual é expressa pelo somatório da diferença entre cada 'y' e cada **'y' estimado** (ajuste/estimativa de 'y' para cada valor de 'x'). A isto denominamos de *Soma de Quadrados do Resíduo* (***SQRes***).  A notação matemática é:

$$
SQRes= \sum (Y_i\ - \hat{Y_i})^2
$$
sendo $i$ cada valor da $i-ésima$ observação da variável preditora 'x'.

Em suma, a porção que o modelo não explica é igual a ***SQRes***



**Notas:** 

* Se $Y \sim N(\mu; \sigma^2)$, então, podemos provar matematicamente que $E(Y_i) = \bar{Y_i} = \hat{Y_i}$ (não faremos essa dedução matemática neste curso)
* O ajuste do modelo linear no R pode ser realizado com a função `lm`. Iremos utilizar no contexto do método dos **Mínimos Quadrados**
* Cada $\hat{Y_i}$ assocido à $i-ésima$ variável preditora 'x' terá o mesmo valor. Utilize a função `fitted` para checar.

```{r Reta 2}
# Plotando o gráfico com 'labels' nos eixos
plot(dt2$y ~ dt2$x, xlab = "Variável regressora 'x'", ylab = "Variável resposta 'y'")

# Escrevendo o título do gráfico
mtext(expression(paste(y != hat(y), " = b0 + b1x + ", bold(e))))
mtext("2)", side = 3, adj = 0)

  ## Reta da média geral
abline(h = mean(dt2$y), col = "red")

  ## Testo da reta Média geral
text(paste("__ Média Geral (", round(mean(dt2$y), 2), ")"), x = 3, y = 19, col = "red")

# Obtendo a soma de quadrados totais ==> SQT
SQT <- sum((dt2$y - mean(dt2$y))^2)

# Escrevendo SQT no gráfico
text(paste("SQT = ", round(SQT, 2)), x = 8, y = 13, col = "red")

# Plotando a linha, fornecendo o intercepto (b0 = 0) e a inclinação (b1 = 1) da reta
  ## Obtendo os coeficientes para obtenção da reta: função `lm`
Reta <- lm(Y ~ x, data = dt2)

  ## Reta da média de cada valor da variável regressora
abline(Reta, col = "blue")

  ## Testo da reta da regressão
text("__ Reta da Regressão", x = 2.82, y = 18, col = "blue")

  ## Obtendo a soma de quadrados residuais == SQRes

    ### Observe os valores retornados com a função `fitted`
SQRes <- sum((dt2$y - fitted(Reta))^2)

  ## Escrevendo SQRes no gráfico
text(paste("SQRes = ", round(SQRes, 2)), x = 8, y = 12, col = "blue")
```

### 2.2. Falta de ajuste do modelo de regressão

Observamos que no modelo ajustado há um fator resídual, o qual é devido aos erros aleatórios oriundos de fatores que não são comtemplados no modelo e, por sua vez, estão associados à variabilidade dos dados. Assim, o erro ou resíduo, possui duas porções:



![*¹Composição do resíduo*](/english/post/Aula6_Regressao_v1_files/Residuo_EP_FA.jpg)

O **erro puro** representa o desvio de cada observação $Y_i$ associado à um valor $i$ da variável regressora, isto é $x_i$. Portanto, é como se tivessemos uma distribuição de dados ('y') para cada valor da variável regressora 'x'. Podemos visualizar melhor na figura abaixo, o qual representa um modelo ajustado, cujo fator residual é composto somente por erro puro. 

![***²Sem** falta de ajuste no modelo ajustado: Somente **erro puro** compondo o resíduo*](/english/post/Aula6_Regressao_v1_files/FaltaAjust1.png)

Quando o modelo ajustado não representa, ou o faz pobremente, a associação entre as variáveis alvo, há um erro associado à falta de ajuste do modelo. Por isso, devemos testar o modelo ajustado quanto a falta de ajuste, de modo a **encontrar um modelo apropriado aos dados**.


![***³Com** falta de ajuste no modelo ajustado: **Erro puro + Falta de ajuste** compondo o resíduo*](/english/post/Aula6_Regressao_v1_files/FaltaAjust2.png)


Para analisar a falta de ajuste do modelo, podemos decompor **SQRes** em duas porções: **Erro puro (EP)** e **Falta de Ajuste (FA)**, como segue.

![](/english/post/Aula6_Regressao_v1_files/TabelaFaltaAjuste.jpg)

Figuras ¹, ² e ³: [mensuração florestal](http://mensuracaoflorestal.com.br/falta-de-ajustamento)

* Obtendo a tabela da ANOVA para:

  *  Testar a significância do modelo de regressão
  *  Obter as somas de quadrados
  *  Obter os coeficientes estimados $\hat{\beta_0}$ (intercepto) e $\hat{\beta_1}$ (inclinação)
  *  Obter a equação da reta: $\hat{Y} = \hat{\beta_0} \ + \hat{\beta_1}X$
  
```{r anova}
# tabela da ANOVA
anova <- anova(Reta)
anova
```
Observamos que a regressão é significativa

* Obtendo os coeficientes: Função `coef`
```{r coef}
coef(Reta)
```

* Interpretação: 

  *  $\hat{\beta_0} = Intercepto:$ Representa o valor de 'y' quando a variável regressora 'x' assume o valor 0, ou seja, quanto é 'y' quando não há o efeito de 'x': ~ 10,36.
  *  $\hat{\beta_1} = Inclinação:$  Representa a variação de 'y' para cada unidade de mudança de 'x': ~ 0,93, ou seja, a cada mudança de 1 unidade de 'x' há uma mudança de ~ 0,93 unidade de 'y'.
  

Vamos obter a equação completa com o auxílio da função `extract_eq` do pacote `equatiomatic`

```{r equation 1, eval=FALSE, echo=F}
equatiomatic::extract_eq(Reta, use_coefs = T)
```


$$
\operatorname{\widehat{Y}} = 10.36 + 0.93(\operatorname{x})
$$

Para se testar a falta de ajuste, compara-se o modelo ajustado anteriormente com um modelo ajustado, agora, considerando 'x' como um **fator**. Isso permitirá verificar se a reta passa pela distribuição de cada valor de 'x'.

A hipótese $H_0$ é que o valor estimado da reta ($\hat{Y_i}$) no ponto $x_i$ está contido na distribuição dos dados no ponto $x_i$.

```{r}
# Teste de falta de ajuste
# Se há repetições ('y') de X
  ## Ajustando o modelo com 'x' como fator
Reta2 <- lm(Y ~ factor(x), data = dt2)
  ## Ajustando a `anova` para comparação de modelos
anova_FA <- anova(Reta, Reta2)
anova_FA
```

Nesse exemplo aceitamos $H_0$ e, dizemos que não há falta de ajuste. Portanto, a porção de resíduos ($\epsilon$) contém apenas o erro puro.

* Obtendo variável com associação quadrática

```{r y2}
# Obtendo y2
dt2$y2 <- dt2$x^2 + dt2$y
dt2
```

* Plotando y2

```{r plot y2 1}
# Plotando o gráfico com 'labels' nos eixos
plot(dt2$y2 ~ dt2$x, xlab = "Variável regressora 'x'", ylab = "Variável resposta 'y'")
Reta3 <- lm(y2 ~ x, data = dt2)

  ## Reta da média de cada valor da variável regressora
abline(Reta3, col = "blue")
```

```{r anova 2}
# Teste de falta de ajuste
# Se há repetições ('y') de X
  ## Ajustando o modelo com 'x' como fator
Reta4 <- lm(y2 ~ factor(x), data = dt2)
  ## Ajustando a `anova` para comparação de modelos
anova_FA2 <- anova(Reta3, Reta4)
anova_FA2
```

Nesse exemplo rejeitamos $H_0$ e, dizemos que há falta de ajuste. Portanto, a porção de resíduos ($\epsilon$) contém o erro puro e falta de ajuste. Nesse caso, devemos encontrar e utilizar um modelo apropriado aos dados.

## {#Referências}
## Referências

MONTGOMERY, Douglas C.; PECK, Elizabeth A.; VINING, G. Geoffrey. **Introduction to linear regression analysis**. John Wiley & Sons, 2021.

# Prática: Regressão Evapotranspiração (**ETP**) vs Produção de massa seca (**MSC**) em mudas de eucalipto


## 1. Explorando tendências de associação entre variáveis

```{r pct, message=F, warning=F}
library(tidyverse)
```

* O **conjunto de dados** consiste em:

  * Um experimento conduzido em **casa de vegetação**
  * **Cultura:** [**Eucalipto**]{style="color: green"}
  * **Material:** Clones comerciais
  * **Tratamentos:** 
    
    * Regimes de irrigação na parcela (R1 - Sem restrição hídrica, R2 - Com restrição hidrica e R3 - Com estresse hídrico)
    * Mudas de clones de eucalipto na subparcela
  
  * Nº de repetições/bloco: 6
  * Nº de plantas por parcela: 1
  * **Caracteres estudados:** Evapotranspiração (ETP) e massa seca de caule e galhos (MSC)
  
Fonte dos dados e maiores detalhes em: [Araujo, 2018](https://repositorio.unesp.br/bitstream/handle/11449/180449/araujo_mj_dr_jabo.pdf?sequence=3&isAllowed=y)

**Para obtenção dos dados, clique aqui:** [Link dos dados](mailto:marcio_ok66@hotmail.com; marcio@ipef.br)

```{r data}
Dados <- openxlsx::read.xlsx("DataSet2_v1.xlsx")
head(Dados, 10)
```

### 1.1. Explorando dados por regime de irrigação (RI)
```{r Analise Exp1}
# Considerando todos os clones e RI's
plot(MSC ~ ETP, data = Dados, main = "Todos os regimes de irrigação e clones")

# Analisando por RI
for (i in unique(Dados$Regime)) {
  plot(
    MSC ~ ETP,
    data = Dados %>%
      filter(Regime == i),
    main = paste("Regime de irrigação", i, "e todos os clones")
  )
}
```

### 1.2.Explorando dados por clones
```{r Analise Exp2}
# Considerando todos os clones e RI's
plot(MSC ~ ETP, data = Dados, main = "Todos os regimes de irrigação e clones")

# Analisando por clone
for (i in unique(Dados$Clone)) {
  plot(
    MSC ~ ETP,
    data = Dados %>%
      filter(Clone == i),
    main = paste("Clone", i, "e todos os RI's")
  )
} 


```

## 2. Modelo de Regressão

### 2.1. Ajuste do modelo

#### 2.1.1. Verificando a falta de ajuste
```{r Reg 1}

# Ajustando o modelo de regressão
Mod1 <- lm(MSC ~ ETP, data = Dados)

  ## Verificando a significância da regressão
anova(Mod1)

  ## Obtendo os Betas: b0 e b1 e R²
summary(Mod1)

# Ajustando o modelo para a falta de ajuste
Ajust1 <- lm(MSC ~ as.factor(ETP), data = Dados)
anova(Ajust1)

# Testando a significância da falta de ajuste
anova(Mod1, Ajust1)
```

```{r report, eval=F, echo=F, results=F}
# install.packages("report")
# report::report(anova(Mod1))
```


* Plotando a regressão
```{r Reg 2}
# Extraindo b0 e b1
b0 <- coef(Mod1)[1]
b1 <- coef(Mod1)[2]

# Plotando os pontos
plot(MSC ~ ETP, data = Dados)

# Inserindo a reta
abline(coef = c(b0, b1))

# Escrevendo a equação
text(expression(paste(hat(y), " = 3.19 + 0.52*ETP")), x = 25, y = 35)

# Inserindo o R²
#summary(Mod1)["r.squared"]
text(paste("R² = ",round(summary(Mod1)[["r.squared"]], 2)), x = 25, y = 30)

```

```{r eq1, eval=F, echo=F}
equatiomatic::extract_eq(Mod1, use_coefs = T)
```

$$
\operatorname{\widehat{MSC}} = 3.19 + 0.52(\operatorname{ETP})
$$


**Conclusões:** 

* O modelo ajustado não contém uma falta de ajuste, ou seja, a porção residual contém apenas o **erro puro**.  
* Há uma associação linear e positiva entre a evapotranspiração dos clones e a produção de massa seca nas mudas avaliadas.
* O modelo explica 41% da variação dos dados, ou seja, 41% da produção de massa seca está associada à evapotranspiração.

### 2.2. Regressão com variável classificatória: **Regressão Múltipla**

Até agora, verificamos a associação entre ETP e MSC sem considerar efeitos que podem ser influenciadores nessa relação. Por exemplo, podemos verificar se:

 * O regime de irrigação aplicado tem influência nessa associação? Se sim, como ocorre? Quais diferenças entre os regimes mais restritivos e o menos restritivo?
 * Os clones possuem comportamentos diferentes em relação à ETP e a produção de massa seca? Quais são diferentes entre si?
 * Há interação entre regime de irrigação e clone?

Nesse contexto, verificaremos a influência desses efeitos utilizando a análise de regressão múltipla, com os efeitos de regime de irrigação e clones.  

#### 2.2.1. Análise do efeito de Regime para MSC das plantas

* Verificando efeito de Regime

  *  $H_0:$ A produção de massa seca das plantas não está associada ao **Regime de Irrigação** (RI)
  
```{r mod2}
# Ajustando o modelo
Mod2 <- lm(MSC ~ ETP + Regime, data = Dados %>% mutate(Regime = as.factor(Regime)))
# Verificando a significância dos efeitos
anova(Mod2)
```

Efeito de RI significativo, portanto **rejeita-se** $H_0$ e, conclui-se que a produção de massa seca das plantas depende do RI. Com isso, devemos obter uma regressão para cada RI.


* Primeiramente iremos comparar o modelo com e sem o efeito de RI

  * $H_0:$ RI não afeta a MSC das plantas

```{r comp1}
# Comparando modelos
anova(Mod1, Mod2)
```

**Conclusão:** O efeito de RI é significativo, portanto, rejeitamos $H_0$ e concluimos que RI afeta a MSC das plantas, isto é, pelo menos um RI difere dos demais para MSC.

* Verificando R² e coeficientes
```{r comp2}
# Verificando os coeficientes e R²
summary(Mod2)
# Extraindo os coeficientes
coef(Mod2)
```


**Conclusões:** 

* RI melhorou o modelo.\
  
  * Comparando R² ajustado, houve um aumento de 0,41 (Modelo sem RI) para 0,62 (Modelo com RI)
  
* As plantas em R2 produzem MSC **~ 11g** a mais em relação ao R1 quando todos os demais fatores são mantidos constantes, ou seja, não há ETP
* As plantas em R3 reduzem MSC em **~ 24g** a mais em relação ao R1 quando não há ETP
* Em suma, as plantas com RI mais restritivos são mais responsíveis à ETP/Irrigação/Disponibilidade Hídrica

**Obtendo as as equações:**

* Com os coeficientes em símbolos



```{r eq2, eval=F, echo=F}
equatiomatic::extract_eq(Mod2,intercept = "beta" , use_coefs = F)
```

$$
\operatorname{MSC} = \beta_{0} + \beta_{1}(\operatorname{ETP}) + \beta_{2}(\operatorname{Regime}_{\operatorname{R2}}) + \beta_{3}(\operatorname{Regime}_{\operatorname{R3}}) + \epsilon
$$

* Com os coeficientes numéricos

```{r eq3, eval=F, echo=F}
equatiomatic::extract_eq(Mod2, use_coefs = T)
```

$$
\operatorname{\widehat{MSC}} = -50.66 + 1.66(\operatorname{ETP}) + 11.03(\operatorname{Regime}_{\operatorname{R2}}) + 24.11(\operatorname{Regime}_{\operatorname{R3}})
$$

##### 2.2.1.1. Análise gráfica

```{r prepar1}
# b0 ==> Efeito (Intercepto) de R1
b0 <- coef(Mod2)[1]

# b1 ou Inclinação ==> Efeito de ETP
b1_slope <- coef(Mod2)[2]

# b2 ==> Efeito (intercepto) de R2
b2 <- coef(Mod2)[1] + coef(Mod2)[3]

# b3 ==> Efeito (Intercepto) de R3
b3 <- coef(Mod2)[1] + coef(Mod2)[4]
```

```{r ggplot 1}
# Camada 1: Inserindo coordenadas
ggplot(Dados, aes(x = ETP, y = MSC)) +
  
# Camada 2: Inserindo pontos e mapeando RI por cores  
  geom_point(aes(colour = Regime)) +
  
# Camada 3: Definindo limites para o eixo y  
  scale_y_continuous(limits = c(-51, 41)) +
  
# Camada 4: Definindo limites para o eixo x  
  scale_x_continuous(limits = c(0, 70)) +
  
# Camada 5: Configurando cores manualmente  
  scale_color_manual(values = c("blue", "green", "red")) +
  
# Camada 6: Plotando e configurando as retas  
  geom_abline(
    intercept = c(b0, b2, b3),
    slope = b1_slope,
    colour = c("blue", "green", "red")
  )
```


* Obtendo o mesmo gráfico com "zoom"
```{r ggplot 2}
# Camada 1: Inserindo coordenadas
ggplot(Dados, aes(x = ETP, y = MSC)) +
  
# Camada 2: Inserindo pontos e mapeando RI por cores  
  geom_point(aes(colour = Regime)) +
  
# Camada 3: Configurando cores manualmente  
  scale_color_manual(values = c("blue", "green", "red")) +
  
# Camada 4: Plotando e configurando as retas  
  geom_abline(
    intercept = c(b0, b2, b3),
    slope = b1_slope,
    colour = c("blue", "green", "red")
  )
```


##### 2.2.1.2. Predição e intervalos: Função `predict` 
```{r pred1}
# Dados para a predição
DataPred <-
  data.frame(
    Regime = c("R1", "R2", "R3"),
    ETP = c(100, 100, 100)
  )
DataPred

# Predição com intervalo da predição
predict(Mod2, newdata = DataPred, interval = "prediction")

# Predição com intervalo de confiança
predict(Mod2, newdata = DataPred, interval = "confidence")
```

**Nota:** O intervalo da predição indica uma incerteza em torno de um **valor único**, ao passo que o intevalo de confiança indica uma incerteza em torno dos **valores médios preditos**.

#### 2.2.2. Análise do efeito de Clones para MSC das plantas

```{r mod3}
# Ajustando o modelo
Mod3 <- lm(MSC ~ ETP + Regime + Clone, data = Dados %>% mutate(Regime = as.factor(Regime), Clone = as.factor(Clone)))

# Verificando a significância dos efeitos
anova(Mod3)
```

Efeito de Clone significativo, portanto **rejeita-se** $H_0$ e, conclui-se que a produção de massa seca das plantas depende do Clone. Com isso, devemos obter uma regressão para cada Clone.


* Primeiramente iremos comparar o modelo com e sem o efeito de Clone

  * $H_0:$ RI não afeta a MSC das plantas

```{r comp3}
# Comparando modelos
anova(Mod2, Mod3)
```

**Conclusão:** O efeito de Clone é significativo, portanto, rejeitamos $H_0$ e concluimos que Clone afeta a MSC das plantas, isto é, pelo menos um Clone difere dos demais para MSC.

* Verificando R² e coeficientes
```{r comp4}
# Verificando os coeficientes e R²
summary(Mod3)

# Extraindo os coeficientes
coef(Mod3)

```


**Conclusões:** 

* Clone melhorou o modelo.\
  
  * Comparando R² ajustado, houve um aumento de 0,62 (Modelo sem Clone) para 0,77 (Modelo com Clone)
  
* Houve alteração no efeito de RI se compararmos ao modelo sem efeito de Clone
  
  *  Por exemplo, as plantas em R2 produzem MSC **~ 5g** a mais em relação ao R1 quando todos os demais fatores são mantidos constantes, ou seja, não há ETP. No modelo anterior esse valor foi de **~ 11g**
  
* **Ex:** O C10 produz **~ 9g** de MSC a mais em relação ao C1 (Clone referência ou pivô) quando todos os demais fatores são mantidos constantes, ou seja, não há ETP


#### [Anexando Conhecimento:]{style="color: red"} [Função `aggregate`]{style="color: blue"}

* Usando a função `aggregate` para obter a média de MSC para cada Clone em cada RI 
```{r agg}
aggregate(MSC ~ Regime:Clone, data = Dados %>% 
            mutate(Clone = as.factor(Clone)), mean)
```

**Obtendo as as equações:**

* Com os coeficientes em símbolos



```{r eq4, eval=F, echo=F}
equatiomatic::extract_eq(Mod3,intercept = "beta" , use_coefs = F)
```

$$
\operatorname{MSC} = \beta_{0} + \beta_{1}(\operatorname{ETP}) + \\ \beta_{2}(\operatorname{Regime}_{\operatorname{R2}}) + \\ \beta_{3}(\operatorname{Regime}_{\operatorname{R3}}) + \\ \beta_{4}(\operatorname{Clone}_{\operatorname{C10}}) + \\ \beta_{5}(\operatorname{Clone}_{\operatorname{C2}}) + \\ \beta_{6}(\operatorname{Clone}_{\operatorname{C3}}) + \\ \beta_{7}(\operatorname{Clone}_{\operatorname{C4}}) + \\ \beta_{8}(\operatorname{Clone}_{\operatorname{C5}}) + \\ \beta_{9}(\operatorname{Clone}_{\operatorname{C6}}) + \\ \beta_{10}(\operatorname{Clone}_{\operatorname{C7}}) + \\ \beta_{11}(\operatorname{Clone}_{\operatorname{C8}}) + \\ \beta_{12}(\operatorname{Clone}_{\operatorname{C9}}) + \epsilon
$$

* Com os coeficientes numéricos

```{r eq5, eval=F, echo=F}
equatiomatic::extract_eq(Mod3, use_coefs = T)
```

$$
\operatorname{\widehat{MSC}} = -25.51 + 0.97(\operatorname{ETP}) + \\ 5.52(\operatorname{Regime}_{\operatorname{R2}}) + \\ 11.05(\operatorname{Regime}_{\operatorname{R3}}) + \\ 9.09(\operatorname{Clone}_{\operatorname{C10}}) + \\ 6.42(\operatorname{Clone}_{\operatorname{C2}}) + \\ 8.58(\operatorname{Clone}_{\operatorname{C3}}) + \\ 6.69(\operatorname{Clone}_{\operatorname{C4}}) + \\ 4.51(\operatorname{Clone}_{\operatorname{C5}}) + \\ 11.64(\operatorname{Clone}_{\operatorname{C6}}) + \\ 2.85(\operatorname{Clone}_{\operatorname{C7}}) + \\ 8.59(\operatorname{Clone}_{\operatorname{C8}}) + \\ 6.09(\operatorname{Clone}_{\operatorname{C9}})
$$


### 2.3. Modelos com interação

Até aqui, os modelos utilizados possuem como premissa haver a mesma inclinação para os efeitos estudados (Regime e Clone). Isso indica que a produção de MSC ocorre na mesma intensidade para todos os regimes e clones, o que pode não estar ocorrendo na prática. Por isso, vamos testar o efeito das interações **ETP:Regime**, **ETP:Clone** e **ETP:Regime:Clone**. Na prática, na observância de significância desses efeitos, o que teremos é diferentes inclinações $(\gamma)$


```{r mod4 1}
# Ajustando o modelo
Mod4 <-
  lm(
    MSC ~ ETP + Clone + Regime + ETP:Regime + ETP:Clone + ETP:Regime:Clone,
    data = Dados %>% mutate(Regime = as.factor(Regime), Clone = as.factor(Clone))
  )

# Verificando a significância dos efeitos
anova(Mod4)
```

Efeito da interação ETP:Regime:Clone não significativo, portanto **aceita-se** $H_0$ e, conclui-se que a mudança de MSC causada pelo efeito de **ETP** é semelhante para todos os regimes e clones estudados.

* Comparando os modelos, temos:

```{r mod4 2}
# Comparando modelos
anova(Mod3, Mod4)
```

* Verificando R² e R² ajustado
```{r mod4 3}
# Verificando os coeficientes e R²
summary(Mod4)[["r.squared"]]

# Verificando os coeficientes e R² ajustado
summary(Mod4)[["adj.r.squared"]]

```

**Conclusões:** 

* A interação não melhorou o modelo.\
  
  * Comparando R² ajustado, não houve um aumento (0,77 se manteve) de um modelo sem e com interação
  * Devemos utilizar o modelo mais **parcimonioso**

#### 2.3.1. Ajustando modelo com interação

Observamos qua não há interação significativa em nosso estudo de caso. No entanto, **vamos supor** que houve interação ETP:Regime significativa, como pocederíamos?

```{r Int 1}
# Ajustando o modelo
Mod5 <-
  lm(MSC ~ ETP + Regime + ETP:Regime,
     data = Dados %>% mutate(Regime = as.factor(Regime)))

# Verificando a significância dos efeitos
anova(Mod5)
```


```{r  mod5 1}
# Verificando os coeficientes e R²
summary(Mod5)

# Extraindo os coeficientes
coef(Mod5)
```


* Com os coeficientes simbólicos

```{r eq7, eval=F, echo=F}
equatiomatic::extract_eq(Mod5, use_coefs = F, intercept = "beta")
```


$$
\operatorname{MSC} = \beta_{0} + \beta_{1}(\operatorname{ETP}) + \\ \beta_{2}(\operatorname{Regime}_{\operatorname{R2}}) + \\ \beta_{3}(\operatorname{Regime}_{\operatorname{R3}}) + \\ \beta_{4}(\operatorname{ETP} \times \operatorname{Regime}_{\operatorname{R2}}) + \\ \beta_{5}(\operatorname{ETP} \times \operatorname{Regime}_{\operatorname{R3}}) + \epsilon
$$

* Com os coeficientes numéricos

```{r eq8, eval=F, echo=F}
equatiomatic::extract_eq(Mod5, use_coefs =T, intercept = "beta")
```

$$
\operatorname{\widehat{MSC}} = -44.56 + 1.53(\operatorname{ETP}) + \\ 0.81(\operatorname{Regime}_{\operatorname{R2}}) + \\ 9.07(\operatorname{Regime}_{\operatorname{R3}}) + \\ 0.24(\operatorname{ETP} \times \operatorname{Regime}_{\operatorname{R2}}) + \\ 0.47(\operatorname{ETP} \times \operatorname{Regime}_{\operatorname{R3}})
$$
```{r}
coef(Mod5)

# Obtendo Interceptos:
# b0 ==> Intercepto para R1 
b0 <- coef(Mod5)[1]

# b0_b2 ==> Intercepto para R2
b0_b2 <- coef(Mod5)[1] + coef(Mod5)[3]

# b0_b3 ==> Intercepto para R3
# b1 ==> Inclinação para R1
b0_b3 <- coef(Mod5)[1] + coef(Mod5)[4]

# Obtendo Inclinações:
# b1 ==> Inclinação para R1
b1 <- coef(Mod5)[2]

# b1_b5 ==> Inclinação para R2
b1_b5 <- coef(Mod5)[2] + coef(Mod5)[5]

# b1_b6 ==> Inclinação para R3
b1_b6 <- coef(Mod5)[2] + coef(Mod5)[6]
```

```{r ggplot 5}
# Camada 1: Inserindo coordenadas
ggplot(Dados, aes(x = ETP, y = MSC)) +
  
# Camada 2: Inserindo pontos e mapeando RI por cores  
  geom_point(aes(colour = Regime)) +
  
# Camada 3: Configurando cores manualmente  
  scale_color_manual(values = c("blue", "green", "red")) +
  
# Camada 4: Plotando e configurando as retas  
  geom_abline(
    intercept = c(b0, b0_b2, b0_b3),
    slope = c(b1, b1_b5, b1_b6),
    colour = c("blue", "green", "red")
  ) 
```

* Utilizando `geom_smooth` 
```{r ggplot}
# Camada 1: Inserindo coordenadas
ggplot(Dados, aes(x = ETP, y = MSC)) +
  
# Camada 2: Inserindo pontos e mapeando RI por cores  
  geom_point(aes(colour = Regime)) +
  
# Camada 3: Configurando cores manualmente  
  scale_color_manual(values = c("blue", "green", "red")) +
  
# Camada 4: Plotando e configurando as retas  
  geom_smooth(aes(colour = Regime), method = "lm", se = T)
```

#### 2.3.2. Obtendo R² no gráfico: Função `stat_cor`

* Instale o pacote `ggpubr`
```{r ggpurr}
# install.packages("ggpubr")
```

```{r ggplot 6}
# Camada 1: Inserindo coordenadas
ggplot(Dados, aes(x = ETP, y = MSC)) +
  
# Camada 2: Inserindo pontos e mapeando RI por cores  
  geom_point(aes(colour = Regime)) +
  
# Camada 3: Configurando cores manualmente  
  scale_color_manual(values = c("blue", "green", "red")) +
  
# Camada 4: Plotando e configurando as retas  
  geom_abline(
    intercept = c(b0, b0_b2, b0_b3),
    slope = c(b1, b1_b5, b1_b6),
    colour = c("blue", "green", "red")
  ) +
  
# Camada 5: Inserindo R²
    ggpubr::stat_cor(
    aes(label = ..rr.label.., colour = Regime),
    geom = "label",
    size = 4
  )
```

```{r}
summary(lm(MSC ~ ETP, data = Dados %>%
     filter(Regime == "R3")))
```

* Obtendo subconjuntos gráficos com `facet_wrap`
```{r ggplot 7, fig.height=5, fig.width=10}
Fig <-
  # Camada 1: Inserindo coordenadas
  ggplot(Dados, aes(x = ETP, y = MSC)) +
  
  # Camada 2: Inserindo pontos e mapeando Regime por cores
    geom_point(aes(colour = Regime)) +
  
  # Camada 3: Obtendo a Reta de um modelo linear com intervalo de confiança
    geom_smooth(method = lm, aes(colour = Regime), se = T) +
  
  # Camada 4: Obtendo subconjuntos gráficos
    facet_wrap(~ Regime, ncol = 6) +
  
  # Obtendo R²
    ggpubr::stat_cor(
      aes(label = ..rr.label..),
      color = "red",
      geom = "label",
      size = 4
  )

# Imprimindo a figura
Fig
```

* Salvando a figura: Função `ggsave`
```{r}
# Salvando figura em formato .tiff
ggsave(filename = "Fig1_Reg.tiff", plot = Fig, width = 10, height = 5)

# Salvando figura em formato .png
ggsave(filename = "Fig1_Reg.png", plot = Fig, width = 10, height = 5)
```


##### 2.3.3. Predição e intervalos: Função `predict` 
```{r pred2}
# Dados para a predição
DataPred2 <-
  data.frame(
    Clone = c("C1", "C5", "C6", "C1", "C5", "C6", "C1", "C5", "C6"),
    Regime = c("R1", "R1", "R1", "R2", "R2", "R2", "R3", "R3", "R3"),
    ETP = rep(30, 9)
  )
DataPred2

# Predição com intervalo da predição
predict(Mod4, newdata = DataPred2, interval = "prediction")

# Predição com intervalo de confiança
data.frame(DataPred2, predict(Mod4, newdata = DataPred2, interval = "confidence"))
```
